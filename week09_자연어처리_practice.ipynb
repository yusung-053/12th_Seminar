{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmUnWsUNXaQ4hBdoCZpZXm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 자연어 처리 주요 코드\n","처음 보는 코드들이라면 당연히 맞출 수 없습니다. 핵심적인 부분을 빈칸으로 만들었기 때문에 답지 보면서 확인하는 정도만 해보세요. 더 관심 있으시면 따로 더 찾아보시는걸 추천드립니다."],"metadata":{"id":"RYsIUrF6Gd3o"}},{"cell_type":"code","source":["# 필수 라이브러리 설치\n","!pip install scikit-learn\n","!pip install gensim\n","!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYTnQw97LHAi","executionInfo":{"status":"ok","timestamp":1762751809490,"user_tz":-540,"elapsed":18878,"user":{"displayName":"김세영","userId":"18361408826094994272"}},"outputId":"0ad6ab50-0410-4f05-9bbb-7f7aa1949913"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEl6DPtCGGo5"},"outputs":[],"source":["# [퀴즈 1: BoW (CountVectorizer)]\n","\n","from sklearn.feature_extraction.text import [_____]  # 1번 빈칸 (BoW 모델)\n","\n","# 2. 분석할 문서 데이터\n","corpus = [\n","    'This is the first document.',\n","    'This document is the second document.',\n","    'And this is the third one.',\n","    'Is this the first document?',\n","]\n","\n","# 3. BoW Vectorizer 객체 생성\n","# (내부적으로 토큰화, 불용어 제거 등을 수행합니다)\n","vectorizer = [_____]()  # 1번 빈칸 (위와 동일)\n","\n","# 4. 문서를 BoW 행렬로 학습 및 변환\n","bow_matrix = vectorizer.[_____](corpus)  # 2번 빈칸 (학습 및 변환)\n","\n","print(\"--- 어휘 사전 (Vocabulary) ---\")\n","# 'get_feature_names_out'은 학습된 단어 목록(사전)을 보여줍니다.\n","print(vectorizer.[_____]())  # 3번 빈칸 (학습된 단어 목록 가져오기)\n","\n","print(\"--- BoW 행렬 (결과) ---\")\n","print(bow_matrix.toarray())"]},{"cell_type":"code","source":["# [퀴즈 2: Word2Vec (gensim)]\n","\n","from gensim.models import [_____]  # 1번 빈칸 (Word2Vec 모델)\n","\n","# 2. 학습할 문장 데이터 (이미 토큰화 완료)\n","sentences = [\n","    ['I', 'love', 'nlp'],\n","    ['I', 'love', 'deep', 'learning'],\n","    ['nlp', 'is', 'fun'],\n","    ['deep', 'learning', 'is', 'fun']\n","]\n","\n","# 3. Word2Vec 모델 학습\n","# vector_size=100 : 단어를 100차원 벡터로 만듦\n","# window=2 : 주변 2개 단어까지 문맥으로 참고\n","# min_count=1 : 최소 1번 이상 나온 단어만 학습\n","model = [_____](\n","    [_____]=sentences,  # 2번 빈칸 (학습 데이터)\n","    vector_size=100,\n","    window=2,\n","    min_count=1\n",")\n","\n","# 4. 'nlp' 단어의 학습된 벡터 확인\n","vector_nlp = model.[_____]['nlp']  # 3번 빈칸 (단어 벡터 접근)\n","\n","print(f\"--- 'nlp'의 100차원 벡터 ---\")\n","print(vector_nlp)\n","\n","# 5. 'nlp'와 가장 유사한 단어 찾기\n","similar_words = model.[_____].most_similar('nlp')  # 4번 빈칸 (유사 단어 찾기)\n","print(f\"\\n--- 'nlp'와 가장 유사한 단어 ---\")\n","print(similar_words)"],"metadata":{"id":"I65olYhOGQHQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import [_____]     # 1번 빈칸 (모델 뼈대)\n","from tensorflow.keras.layers import [_____], [_____], [_____]  # 2, 3, 4번 빈칸\n","from tensorflow.keras.preprocessing.text import [_____]      # 5번 빈칸 (전처리)\n","from tensorflow.keras.preprocessing.sequence import [_____]  # 6번 빈칸 (전처리)\n","\n","# 1. 데이터 준비 (긍정=1, 부정=0)\n","texts = ['This movie is great', 'I love this film', 'This is terrible', 'I hate this movie']\n","labels = np.array([1, 1, 0, 0])\n","\n","# 2. 텍스트 전처리 (Tokenizer)\n","vocab_size = 100  # 단어 사전 크기를 100개로 제한\n","tokenizer = [_____](num_words=vocab_size)  # 5번 빈칸\n","tokenizer.[_____](texts)               # 7번 빈칸 (단어 사전 학습)\n","sequences = tokenizer.[_____](texts)      # 8번 빈칸 (텍스트를 숫자 시퀀스로)\n","\n","print(\"--- 숫자 시퀀스 변환 ---\")\n","print(sequences)\n","\n","# 3. 텍스트 전처리 (Padding)\n","max_len = 10  # 모든 문장 길이를 10으로 맞춤\n","padded_data = [_____](sequences, maxlen=max_len)  # 6번 빈칸\n","\n","print(\"\\n--- 패딩 완료 (길이 10) ---\")\n","print(padded_data)\n","\n","# 4. 모델 구축\n","model = [_____]()  # 1번 빈칸\n","model.add([_____](input_dim=vocab_size, output_dim=32, input_length=max_len)) # 2번 빈칸\n","model.add([_____](units=64))  # 3번 빈칸\n","model.add([_____](units=1, activation='sigmoid'))  # 4번 빈칸\n","\n","# 5. 모델 컴파일 (학습 설정)\n","model.[_____](optimizer='adam',\n","             [_____]='binary_crossentropy',  # 9번, 10번 빈칸\n","             metrics=['accuracy'])\n","\n","# 6. 모델 훈련\n","model.[_____](padded_data, labels, [_____]=20)  # 11번, 12번 빈칸\n","\n","# 7. [퀴즈] 새로운 데이터 예측\n","test_text = ['I love this great movie']\n","test_seq = tokenizer.texts_to_sequences(test_text)\n","test_pad = pad_sequences(test_seq, maxlen=max_len)\n","\n","prediction = model.[_____](test_pad)  # 13번 빈칸\n","print(f\"\\n--- 예측 결과 ('I love this great movie'는?) ---\")\n","print(prediction) # 1에 가까우면 긍정"],"metadata":{"id":"cpsjl3rVGT-J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["자연어 처리에서 가장 유명한 논문이 \"Attention Is All You Need\"입니다. 자연어 처리에 관심이 있으신 분들인 이 논문을 꼭 읽어보시는걸 추천드립니다. (읽으면서 모르는건 생성형 AI에 질문해보세요.)"],"metadata":{"id":"NAlJH6fJHXmX"}}]}