{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPtiP5IM3xIoxWnf0Eija8S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# 필수 라이브러리 설치\n","!pip install scikit-learn\n","!pip install gensim\n","!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PIU0QZaLSU5","executionInfo":{"status":"ok","timestamp":1762752695382,"user_tz":-540,"elapsed":17726,"user":{"displayName":"김세영","userId":"18361408826094994272"}},"outputId":"5364b2b1-2079-45b8-836f-ecfe2a67242a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsEHGyLZJXFE","executionInfo":{"status":"ok","timestamp":1762751223787,"user_tz":-540,"elapsed":37,"user":{"displayName":"김세영","userId":"18361408826094994272"}},"outputId":"493a57c2-433d-466c-f646-6d6e0132a01a"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 어휘 사전 (Vocabulary) ---\n","['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n","--- BoW 행렬 (결과) ---\n","[[0 1 1 1 0 0 1 0 1]\n"," [0 2 0 1 0 1 1 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 1 0 0 1 0 1]]\n"]}],"source":["# [퀴즈 1: BoW (CountVectorizer)]\n","\n","from sklearn.feature_extraction.text import CountVectorizer  # 1번 빈칸 (BoW 모델)\n","\n","# 2. 분석할 문서 데이터\n","corpus = [\n","    'This is the first document.',\n","    'This document is the second document.',\n","    'And this is the third one.',\n","    'Is this the first document?',\n","]\n","\n","# 3. BoW Vectorizer 객체 생성\n","# (내부적으로 토큰화, 불용어 제거 등을 수행합니다)\n","vectorizer = CountVectorizer()  # 1번 빈칸 (위와 동일)\n","\n","# 4. 문서를 BoW 행렬로 학습 및 변환\n","bow_matrix = vectorizer.fit_transform(corpus)  # 2번 빈칸 (학습 및 변환)\n","\n","print(\"--- 어휘 사전 (Vocabulary) ---\")\n","# 'get_feature_names_out'은 학습된 단어 목록(사전)을 보여줍니다.\n","print(vectorizer.get_feature_names_out())  # 3번 빈칸 (학습된 단어 목록 가져오기)\n","\n","print(\"--- BoW 행렬 (결과) ---\")\n","print(bow_matrix.toarray())"]},{"cell_type":"code","source":["# [퀴즈 2: Word2Vec (gensim)]\n","\n","from gensim.models import Word2Vec  # 1번 빈칸 (Word2Vec 모델)\n","\n","# 2. 학습할 문장 데이터 (이미 토큰화 완료)\n","sentences = [\n","    ['I', 'love', 'nlp'],\n","    ['I', 'love', 'deep', 'learning'],\n","    ['nlp', 'is', 'fun'],\n","    ['deep', 'learning', 'is', 'fun']\n","]\n","\n","# 3. Word2Vec 모델 학습\n","# vector_size=100 : 단어를 100차원 벡터로 만듦\n","# window=2 : 주변 2개 단어까지 문맥으로 참고\n","# min_count=1 : 최소 1번 이상 나온 단어만 학습\n","model = Word2Vec(\n","    sentences=sentences,  # 2번 빈칸 (학습 데이터)\n","    vector_size=100,\n","    window=2,\n","    min_count=1\n",")\n","\n","# 4. 'nlp' 단어의 학습된 벡터 확인\n","vector_nlp = model.wv['nlp']  # 3번 빈칸 (단어 벡터 접근)\n","\n","print(f\"--- 'nlp'의 100차원 벡터 ---\")\n","print(vector_nlp)\n","\n","# 5. 'nlp'와 가장 유사한 단어 찾기\n","similar_words = model.wv.most_similar('nlp')  # 4번 빈칸 (유사 단어 찾기)\n","print(f\"\\n--- 'nlp'와 가장 유사한 단어 ---\")\n","print(similar_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G20EIvQXKTHh","executionInfo":{"status":"ok","timestamp":1762751628137,"user_tz":-540,"elapsed":1012,"user":{"displayName":"김세영","userId":"18361408826094994272"}},"outputId":"5e196779-db8b-4b06-81ed-2b343da0d00c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 'nlp'의 100차원 벡터 ---\n","[-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n","  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n"," -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n","  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n"," -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n","  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n"," -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n"," -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n","  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n"," -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n","  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n","  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n"," -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n","  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n"," -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n","  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n","  0.00620989  0.00481889  0.00078719  0.00301345]\n","\n","--- 'nlp'와 가장 유사한 단어 ---\n","[('learning', 0.17018885910511017), ('love', 0.13887983560562134), ('I', 0.03476494923233986), ('is', 0.004503022879362106), ('fun', -0.027750348672270775), ('deep', -0.04461711645126343)]\n"]}]},{"cell_type":"code","source":["# [퀴즈 3: LSTM 모델 (Keras) - 정답]\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential     # 1번 정답\n","from tensorflow.keras.layers import Embedding, LSTM, Dense  # 2, 3, 4번 정답\n","from tensorflow.keras.preprocessing.text import Tokenizer      # 5번 정답\n","from tensorflow.keras.preprocessing.sequence import pad_sequences  # 6번 정답\n","\n","# 1. 데이터 준비 (긍정=1, 부정=0)\n","texts = ['This movie is great', 'I love this film', 'This is terrible', 'I hate this movie']\n","labels = np.array([1, 1, 0, 0])\n","\n","# 2. 텍스트 전처리 (Tokenizer)\n","vocab_size = 100\n","tokenizer = Tokenizer(num_words=vocab_size)  # 5번 정답\n","tokenizer.fit_on_texts(texts)               # 7번 정답\n","sequences = tokenizer.texts_to_sequences(texts)      # 8번 정답\n","\n","print(\"--- 숫자 시퀀스 변환 ---\")\n","print(sequences)\n","\n","# 3. 텍스트 전처리 (Padding)\n","max_len = 10\n","padded_data = pad_sequences(sequences, maxlen=max_len)  # 6번 정답\n","\n","print(\"\\n--- 패딩 완료 (길이 10) ---\")\n","print(padded_data)\n","\n","# 4. 모델 구축\n","model = Sequential()  # 1번 정답\n","model.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len)) # 2번 정답\n","model.add(LSTM(units=64))  # 3번 정답\n","model.add(Dense(units=1, activation='sigmoid'))  # 4번 정답\n","\n","# 5. 모델 컴파일 (학습 설정)\n","model.compile(optimizer='adam',\n","             loss='binary_crossentropy',  # 9번, 10번 정답\n","             metrics=['accuracy'])\n","\n","# 6. 모델 훈련\n","model.fit(padded_data, labels, epochs=20)  # 11번, 12번 정답\n","\n","# 7. [퀴즈] 새로운 데이터 예측\n","test_text = ['I love this great movie']\n","test_seq = tokenizer.texts_to_sequences(test_text)\n","test_pad = pad_sequences(test_seq, maxlen=max_len)\n","\n","prediction = model.predict(test_pad)  # 13번 정답\n","print(f\"\\n--- 예측 결과 ('I love this great movie'는?) ---\")\n","print(prediction) # 1에 가까우면 긍정"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jWynvn-L1EH","executionInfo":{"status":"ok","timestamp":1762752718417,"user_tz":-540,"elapsed":8812,"user":{"displayName":"김세영","userId":"18361408826094994272"}},"outputId":"e19f6c98-e819-4a0b-9741-d761c82b336f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 숫자 시퀀스 변환 ---\n","[[1, 2, 3, 5], [4, 6, 1, 7], [1, 3, 8], [4, 9, 1, 2]]\n","\n","--- 패딩 완료 (길이 10) ---\n","[[0 0 0 0 0 0 1 2 3 5]\n"," [0 0 0 0 0 0 4 6 1 7]\n"," [0 0 0 0 0 0 0 1 3 8]\n"," [0 0 0 0 0 0 4 9 1 2]]\n","Epoch 1/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.5000 - loss: 0.6945\n","Epoch 2/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2500 - loss: 0.6934\n","Epoch 3/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5000 - loss: 0.6922\n","Epoch 4/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.6911\n","Epoch 5/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7500 - loss: 0.6899\n","Epoch 6/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7500 - loss: 0.6887\n","Epoch 7/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.6875\n","Epoch 8/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.6862\n","Epoch 9/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.6849\n","Epoch 10/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.6834\n","Epoch 11/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.6819\n","Epoch 12/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.6803\n","Epoch 13/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.6785\n","Epoch 14/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.6766\n","Epoch 15/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.6746\n","Epoch 16/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.6724\n","Epoch 17/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6700\n","Epoch 18/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6675\n","Epoch 19/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6647\n","Epoch 20/20\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6617\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n","\n","--- 예측 결과 ('I love this great movie'는?) ---\n","[[0.5198841]]\n"]}]}]}